{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will train and validate a number of Machine Learning algorithms to classify reports as either positive or negative for fluid collection.\n",
    "\n",
    "The first part of this will read in the data and transform it from free text into sparse vectors. The second part will train the algorithms and evaluate their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "Right now the data is stored in a sqlite database. There are two main columns:\n",
    "- ``text``: the free text of the radiology report\n",
    "- ``doc_class``: a 1 if there is a fluid collection, 0 if there isn't.\n",
    "\n",
    "They need to be represented as sparse vectors. We'll read them in, preprocess them, and convert them using ``sklearn``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3 as sqlite\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score,accuracy_score, precision_score, recall_score, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils import shuffle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATADIR = '../stats_data'\n",
    "DB = os.path.join(DATADIR, 'Reference Standard', 'radiology_reports.sqlite')\n",
    "os.path.exists(DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite.connect(DB)\n",
    "\n",
    "# Training data\n",
    "train_df = pd.read_sql(\"SELECT * FROM training_notes;\", conn)\n",
    "#Testing data\n",
    "test_df = pd.read_sql(\"SELECT * FROM testing_notes;\", conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowid</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>referenceXML</th>\n",
       "      <th>doc_class</th>\n",
       "      <th>subject</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No_10792_131562_05-29-20</td>\n",
       "      <td>\\n CT ABDOMEN W/CONTRAST; CT PELVIS W/CONTRAS...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;annot...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>131562</td>\n",
       "      <td>05-29-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No_11050_126785_11-03-33</td>\n",
       "      <td>\\n CT CHEST W/CONTRAST; CT ABDOMEN W/CONTRAST...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;annot...</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>126785</td>\n",
       "      <td>11-03-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No_11879_166554_06-22-37</td>\n",
       "      <td>\\n CTA CHEST W&amp;W/O C &amp;RECONS; CT 100CC NON IO...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;annot...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>166554</td>\n",
       "      <td>06-22-37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No_11879_166554_06-23-37</td>\n",
       "      <td>\\n CT ABDOMEN W/O CONTRAST; CT PELVIS W/O CON...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;annot...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>166554</td>\n",
       "      <td>06-23-37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No_11879_166554_07-02-37</td>\n",
       "      <td>\\n CT CHEST W/O CONTRAST \\n ~ Reason: r/o ste...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;annot...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>166554</td>\n",
       "      <td>07-02-37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rowid                      name  \\\n",
       "0      1  No_10792_131562_05-29-20   \n",
       "1      2  No_11050_126785_11-03-33   \n",
       "2      3  No_11879_166554_06-22-37   \n",
       "3      4  No_11879_166554_06-23-37   \n",
       "4      5  No_11879_166554_07-02-37   \n",
       "\n",
       "                                                text  \\\n",
       "0   \\n CT ABDOMEN W/CONTRAST; CT PELVIS W/CONTRAS...   \n",
       "1   \\n CT CHEST W/CONTRAST; CT ABDOMEN W/CONTRAST...   \n",
       "2   \\n CTA CHEST W&W/O C &RECONS; CT 100CC NON IO...   \n",
       "3   \\n CT ABDOMEN W/O CONTRAST; CT PELVIS W/O CON...   \n",
       "4   \\n CT CHEST W/O CONTRAST \\n ~ Reason: r/o ste...   \n",
       "\n",
       "                                        referenceXML  doc_class  subject  \\\n",
       "0  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<annot...          0       32   \n",
       "1  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<annot...          0       34   \n",
       "2  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<annot...          0       35   \n",
       "3  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<annot...          0       35   \n",
       "4  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<annot...          0       35   \n",
       "\n",
       "   HADM_ID CHARTDATE  \n",
       "0   131562  05-29-20  \n",
       "1   126785  11-03-33  \n",
       "2   166554  06-22-37  \n",
       "3   166554  06-23-37  \n",
       "4   166554  07-02-37  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TfidfVectorizer` and `CountVectorizer` classes transform raw texts into matrices where the rows represent reports and the columns represents terms that are present in that report. `Tfidf` uses *Term-Freqeuncy Inverse-Document Frequency* weighting, while `Count` uses raw counts.\n",
    "\n",
    "We'll use the vectorizer to preprocess the text, as well. We'll make the reports lowercase, remove all stopwords, and extracts ngrams from 1-3. We'll also set a minimum document threshold, stating that an ngram must appear in at least 10% of the documents to be included. This will help cut down on a lot of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.1, lowercase=True, stop_words='english',\n",
    "                                    ngram_range=(1, 3))\n",
    "\n",
    "X_train = list(train_df.text)\n",
    "y_train = list(train_df.doc_class)\n",
    "\n",
    "# Fit the vectorizer and transform the training notes into a vector\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "\n",
    "# Now use this fitted vectorizer to transform the test data\n",
    "X_test = list(test_df.text)\n",
    "y_test = list(test_df.doc_class)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.04251338, 0.04533661, ..., 0.        , 0.06027539,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.02942781,\n",
       "         0.        ],\n",
       "        [0.08356349, 0.        , 0.        , ..., 0.        , 0.04091356,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.05500347, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.04392229, 0.02344006,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.06829954, 0.0364495 ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle the training data\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(545, 682)\n",
      "(100, 682)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our vocabulary consists of 682 ngrams. Our data has 545 training notes and 100 testing notes.\n",
    "\n",
    "Now we can start training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "We'll consider these algorithms as document classifiers:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- Naive Bayes\n",
    "- Linear SVM\n",
    "\n",
    "For each of these, we'll also consider a number of hyper-parameters to try and find the optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(X_train, y_train, X_test, y_test, clf, model_name, results):\n",
    "    print(model_name)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    f1, p, r = (f1_score(y_train, y_pred_train,average='binary'),\n",
    "               precision_score(y_train, y_pred_train, average='binary'),\n",
    "               recall_score(y_train, y_pred_train,average='binary'))\n",
    "    print(\"Train:\")\n",
    "    print(f1, p, r)\n",
    "    results = results.append({'test/train':'train','name':model_name,\n",
    "                              'F1':f1,'Precision':p,'Recall':r,\n",
    "                              \"Classifier\": clf},ignore_index=True)\n",
    "\n",
    "    # Now evaluate on testing data\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    f1, p, r = (f1_score(y_test, y_pred_test, average='binary'),\n",
    "               precision_score(y_test, y_pred_test, average='binary'),\n",
    "               recall_score(y_test, y_pred_test, average='binary'))\n",
    "    print(\"Test:\")\n",
    "    print(f1, p, r)\n",
    "    results = results.append({'test/train':'test', \n",
    "                              'name':model_name,\n",
    "                              'F1':f1, 'Precision':p, 'Recall':r,\n",
    "                             \"Classifier\": clf},\n",
    "                             ignore_index=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This dataframe will keep track of all of our scores\n",
    "results = pd.DataFrame(columns=('test/train','name', 'F1',\"Precision\",\"Recall\", \"Classifier\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: penalty=l1, C=0.01\n",
      "Train:\n",
      "0.0 0.0 0.0\n",
      "Test:\n",
      "0.0 0.0 0.0\n",
      "Logistic Regression: penalty=l1, C=0.1\n",
      "Train:\n",
      "0.07377049180327869 0.9 0.038461538461538464\n",
      "Test:\n",
      "0.17647058823529413 1.0 0.0967741935483871\n",
      "Logistic Regression: penalty=l1, C=0.5\n",
      "Train:\n",
      "0.7358490566037735 0.8210526315789474 0.6666666666666666\n",
      "Test:\n",
      "0.6666666666666667 0.782608695652174 0.5806451612903226\n",
      "Logistic Regression: penalty=l1, C=1.0\n",
      "Train:\n",
      "0.7788018433179723 0.845 0.7222222222222222\n",
      "Test:\n",
      "0.6666666666666667 0.782608695652174 0.5806451612903226\n",
      "Logistic Regression: penalty=l2, C=0.01\n",
      "Train:\n",
      "0.0 0.0 0.0\n",
      "Test:\n",
      "0.0 0.0 0.0\n",
      "Logistic Regression: penalty=l2, C=0.1\n",
      "Train:\n",
      "0.6144927536231884 0.954954954954955 0.452991452991453\n",
      "Test:\n",
      "0.5454545454545454 0.9230769230769231 0.3870967741935484\n",
      "Logistic Regression: penalty=l2, C=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alec/anaconda/envs/i2b2/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/alec/anaconda/envs/i2b2/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "0.8037825059101654 0.8994708994708994 0.7264957264957265\n",
      "Test:\n",
      "0.7777777777777777 0.9130434782608695 0.6774193548387096\n",
      "Logistic Regression: penalty=l2, C=1.0\n",
      "Train:\n",
      "0.8375286041189931 0.9014778325123153 0.782051282051282\n",
      "Test:\n",
      "0.7857142857142856 0.88 0.7096774193548387\n",
      "   test/train                                    name        F1  Precision  \\\n",
      "11       test  Logistic Regression: penalty=l2, C=0.1  0.545455   0.923077   \n",
      "12      train  Logistic Regression: penalty=l2, C=0.5  0.803783   0.899471   \n",
      "13       test  Logistic Regression: penalty=l2, C=0.5  0.777778   0.913043   \n",
      "14      train  Logistic Regression: penalty=l2, C=1.0  0.837529   0.901478   \n",
      "15       test  Logistic Regression: penalty=l2, C=1.0  0.785714   0.880000   \n",
      "\n",
      "      Recall                                         Classifier  \n",
      "11  0.387097  LogisticRegression(C=0.1, class_weight=None, d...  \n",
      "12  0.726496  LogisticRegression(C=0.5, class_weight=None, d...  \n",
      "13  0.677419  LogisticRegression(C=0.5, class_weight=None, d...  \n",
      "14  0.782051  LogisticRegression(C=1.0, class_weight=None, d...  \n",
      "15  0.709677  LogisticRegression(C=1.0, class_weight=None, d...  \n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "penalties = ['l1', 'l2']\n",
    "Cs = [0.01, 0.1, 0.5, 1.0]\n",
    "\n",
    "for penalty in penalties:\n",
    "    for c in Cs:\n",
    "        model_name = \"Logistic Regression: penalty={}, C={}\".format(penalty, c)\n",
    "        clf = LogisticRegression(penalty=penalty, C=c)\n",
    "        \n",
    "        results = train_and_evaluate_model(X_train, y_train, X_test, y_test, clf, model_name, results)\n",
    "print(results.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: n=200, feat=sqrt, depth=50\n",
      "Random Forest: n=200, feat=sqrt, depth=50\n",
      "Train:\n",
      "1.0 1.0 1.0\n",
      "Test:\n",
      "0.7241379310344828 0.7777777777777778 0.6774193548387096\n",
      "Random Forest: n=500, feat=sqrt, depth=50\n",
      "Random Forest: n=500, feat=sqrt, depth=50\n",
      "Train:\n",
      "1.0 1.0 1.0\n",
      "Test:\n",
      "0.7586206896551724 0.8148148148148148 0.7096774193548387\n",
      "Random Forest: n=1000, feat=sqrt, depth=50\n",
      "Random Forest: n=1000, feat=sqrt, depth=50\n",
      "Train:\n",
      "1.0 1.0 1.0\n",
      "Test:\n",
      "0.7368421052631579 0.8076923076923077 0.6774193548387096\n",
      "Random Forest: n=200, feat=sqrt, depth=None\n",
      "Random Forest: n=200, feat=sqrt, depth=None\n",
      "Train:\n",
      "1.0 1.0 1.0\n",
      "Test:\n",
      "0.7368421052631579 0.8076923076923077 0.6774193548387096\n",
      "Random Forest: n=500, feat=sqrt, depth=None\n",
      "Random Forest: n=500, feat=sqrt, depth=None\n",
      "Train:\n",
      "1.0 1.0 1.0\n",
      "Test:\n",
      "0.7586206896551724 0.8148148148148148 0.7096774193548387\n",
      "Random Forest: n=1000, feat=sqrt, depth=None\n",
      "Random Forest: n=1000, feat=sqrt, depth=None\n",
      "Train:\n",
      "1.0 1.0 1.0\n",
      "Test:\n",
      "0.7796610169491526 0.8214285714285714 0.7419354838709677\n",
      "Random Forest: n=200, feat=None, depth=50\n",
      "Random Forest: n=200, feat=None, depth=50\n",
      "Train:\n",
      "1.0 1.0 1.0\n",
      "Test:\n",
      "0.7272727272727272 0.6857142857142857 0.7741935483870968\n",
      "Random Forest: n=500, feat=None, depth=50\n",
      "Random Forest: n=500, feat=None, depth=50\n",
      "Train:\n",
      "1.0 1.0 1.0\n",
      "Test:\n",
      "0.746268656716418 0.6944444444444444 0.8064516129032258\n",
      "Random Forest: n=1000, feat=None, depth=50\n",
      "Random Forest: n=1000, feat=None, depth=50\n",
      "Train:\n",
      "1.0 1.0 1.0\n",
      "Test:\n",
      "0.746268656716418 0.6944444444444444 0.8064516129032258\n",
      "Random Forest: n=200, feat=None, depth=None\n",
      "Random Forest: n=200, feat=None, depth=None\n",
      "Train:\n",
      "1.0 1.0 1.0\n",
      "Test:\n",
      "0.7384615384615385 0.7058823529411765 0.7741935483870968\n",
      "Random Forest: n=500, feat=None, depth=None\n",
      "Random Forest: n=500, feat=None, depth=None\n",
      "Train:\n",
      "1.0 1.0 1.0\n",
      "Test:\n",
      "0.7272727272727272 0.6857142857142857 0.7741935483870968\n",
      "Random Forest: n=1000, feat=None, depth=None\n",
      "Random Forest: n=1000, feat=None, depth=None\n",
      "Train:\n",
      "1.0 1.0 1.0\n",
      "Test:\n",
      "0.7575757575757576 0.7142857142857143 0.8064516129032258\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/train</th>\n",
       "      <th>name</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight=None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight=None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=0.1</td>\n",
       "      <td>0.073770</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=0.1</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=0.5</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>LogisticRegression(C=0.5, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>LogisticRegression(C=0.5, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=1.0</td>\n",
       "      <td>0.778802</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train</td>\n",
       "      <td>Logistic Regression: penalty=l2, C=0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight=None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l2, C=0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight=None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>train</td>\n",
       "      <td>Logistic Regression: penalty=l2, C=0.1</td>\n",
       "      <td>0.614493</td>\n",
       "      <td>0.954955</td>\n",
       "      <td>0.452991</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l2, C=0.1</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>train</td>\n",
       "      <td>Logistic Regression: penalty=l2, C=0.5</td>\n",
       "      <td>0.803783</td>\n",
       "      <td>0.899471</td>\n",
       "      <td>0.726496</td>\n",
       "      <td>LogisticRegression(C=0.5, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l2, C=0.5</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>LogisticRegression(C=0.5, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>train</td>\n",
       "      <td>Logistic Regression: penalty=l2, C=1.0</td>\n",
       "      <td>0.837529</td>\n",
       "      <td>0.901478</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l2, C=1.0</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>train</td>\n",
       "      <td>Random Forest: n=200, feat=sqrt, depth=50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=200, feat=sqrt, depth=50</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>train</td>\n",
       "      <td>Random Forest: n=500, feat=sqrt, depth=50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=500, feat=sqrt, depth=50</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>train</td>\n",
       "      <td>Random Forest: n=1000, feat=sqrt, depth=50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=1000, feat=sqrt, depth=50</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>train</td>\n",
       "      <td>Random Forest: n=200, feat=sqrt, depth=None</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=200, feat=sqrt, depth=None</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>train</td>\n",
       "      <td>Random Forest: n=500, feat=sqrt, depth=None</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=500, feat=sqrt, depth=None</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>train</td>\n",
       "      <td>Random Forest: n=1000, feat=sqrt, depth=None</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=1000, feat=sqrt, depth=None</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>train</td>\n",
       "      <td>Random Forest: n=200, feat=None, depth=50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=200, feat=None, depth=50</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>train</td>\n",
       "      <td>Random Forest: n=500, feat=None, depth=50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=500, feat=None, depth=50</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>train</td>\n",
       "      <td>Random Forest: n=1000, feat=None, depth=50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=1000, feat=None, depth=50</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>train</td>\n",
       "      <td>Random Forest: n=200, feat=None, depth=None</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=200, feat=None, depth=None</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>train</td>\n",
       "      <td>Random Forest: n=500, feat=None, depth=None</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=500, feat=None, depth=None</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>train</td>\n",
       "      <td>Random Forest: n=1000, feat=None, depth=None</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=1000, feat=None, depth=None</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test/train                                          name        F1  \\\n",
       "0       train       Logistic Regression: penalty=l1, C=0.01  0.000000   \n",
       "1        test       Logistic Regression: penalty=l1, C=0.01  0.000000   \n",
       "2       train        Logistic Regression: penalty=l1, C=0.1  0.073770   \n",
       "3        test        Logistic Regression: penalty=l1, C=0.1  0.176471   \n",
       "4       train        Logistic Regression: penalty=l1, C=0.5  0.735849   \n",
       "5        test        Logistic Regression: penalty=l1, C=0.5  0.666667   \n",
       "6       train        Logistic Regression: penalty=l1, C=1.0  0.778802   \n",
       "7        test        Logistic Regression: penalty=l1, C=1.0  0.666667   \n",
       "8       train       Logistic Regression: penalty=l2, C=0.01  0.000000   \n",
       "9        test       Logistic Regression: penalty=l2, C=0.01  0.000000   \n",
       "10      train        Logistic Regression: penalty=l2, C=0.1  0.614493   \n",
       "11       test        Logistic Regression: penalty=l2, C=0.1  0.545455   \n",
       "12      train        Logistic Regression: penalty=l2, C=0.5  0.803783   \n",
       "13       test        Logistic Regression: penalty=l2, C=0.5  0.777778   \n",
       "14      train        Logistic Regression: penalty=l2, C=1.0  0.837529   \n",
       "15       test        Logistic Regression: penalty=l2, C=1.0  0.785714   \n",
       "16      train     Random Forest: n=200, feat=sqrt, depth=50  1.000000   \n",
       "17       test     Random Forest: n=200, feat=sqrt, depth=50  0.724138   \n",
       "18      train     Random Forest: n=500, feat=sqrt, depth=50  1.000000   \n",
       "19       test     Random Forest: n=500, feat=sqrt, depth=50  0.758621   \n",
       "20      train    Random Forest: n=1000, feat=sqrt, depth=50  1.000000   \n",
       "21       test    Random Forest: n=1000, feat=sqrt, depth=50  0.736842   \n",
       "22      train   Random Forest: n=200, feat=sqrt, depth=None  1.000000   \n",
       "23       test   Random Forest: n=200, feat=sqrt, depth=None  0.736842   \n",
       "24      train   Random Forest: n=500, feat=sqrt, depth=None  1.000000   \n",
       "25       test   Random Forest: n=500, feat=sqrt, depth=None  0.758621   \n",
       "26      train  Random Forest: n=1000, feat=sqrt, depth=None  1.000000   \n",
       "27       test  Random Forest: n=1000, feat=sqrt, depth=None  0.779661   \n",
       "28      train     Random Forest: n=200, feat=None, depth=50  1.000000   \n",
       "29       test     Random Forest: n=200, feat=None, depth=50  0.727273   \n",
       "30      train     Random Forest: n=500, feat=None, depth=50  1.000000   \n",
       "31       test     Random Forest: n=500, feat=None, depth=50  0.746269   \n",
       "32      train    Random Forest: n=1000, feat=None, depth=50  1.000000   \n",
       "33       test    Random Forest: n=1000, feat=None, depth=50  0.746269   \n",
       "34      train   Random Forest: n=200, feat=None, depth=None  1.000000   \n",
       "35       test   Random Forest: n=200, feat=None, depth=None  0.738462   \n",
       "36      train   Random Forest: n=500, feat=None, depth=None  1.000000   \n",
       "37       test   Random Forest: n=500, feat=None, depth=None  0.727273   \n",
       "38      train  Random Forest: n=1000, feat=None, depth=None  1.000000   \n",
       "39       test  Random Forest: n=1000, feat=None, depth=None  0.757576   \n",
       "\n",
       "    Precision    Recall                                         Classifier  \n",
       "0    0.000000  0.000000  LogisticRegression(C=0.01, class_weight=None, ...  \n",
       "1    0.000000  0.000000  LogisticRegression(C=0.01, class_weight=None, ...  \n",
       "2    0.900000  0.038462  LogisticRegression(C=0.1, class_weight=None, d...  \n",
       "3    1.000000  0.096774  LogisticRegression(C=0.1, class_weight=None, d...  \n",
       "4    0.821053  0.666667  LogisticRegression(C=0.5, class_weight=None, d...  \n",
       "5    0.782609  0.580645  LogisticRegression(C=0.5, class_weight=None, d...  \n",
       "6    0.845000  0.722222  LogisticRegression(C=1.0, class_weight=None, d...  \n",
       "7    0.782609  0.580645  LogisticRegression(C=1.0, class_weight=None, d...  \n",
       "8    0.000000  0.000000  LogisticRegression(C=0.01, class_weight=None, ...  \n",
       "9    0.000000  0.000000  LogisticRegression(C=0.01, class_weight=None, ...  \n",
       "10   0.954955  0.452991  LogisticRegression(C=0.1, class_weight=None, d...  \n",
       "11   0.923077  0.387097  LogisticRegression(C=0.1, class_weight=None, d...  \n",
       "12   0.899471  0.726496  LogisticRegression(C=0.5, class_weight=None, d...  \n",
       "13   0.913043  0.677419  LogisticRegression(C=0.5, class_weight=None, d...  \n",
       "14   0.901478  0.782051  LogisticRegression(C=1.0, class_weight=None, d...  \n",
       "15   0.880000  0.709677  LogisticRegression(C=1.0, class_weight=None, d...  \n",
       "16   1.000000  1.000000  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "17   0.777778  0.677419  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "18   1.000000  1.000000  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "19   0.814815  0.709677  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "20   1.000000  1.000000  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "21   0.807692  0.677419  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "22   1.000000  1.000000  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "23   0.807692  0.677419  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "24   1.000000  1.000000  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "25   0.814815  0.709677  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "26   1.000000  1.000000  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "27   0.821429  0.741935  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "28   1.000000  1.000000  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "29   0.685714  0.774194  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "30   1.000000  1.000000  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "31   0.694444  0.806452  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "32   1.000000  1.000000  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "33   0.694444  0.806452  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "34   1.000000  1.000000  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "35   0.705882  0.774194  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "36   1.000000  1.000000  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "37   0.685714  0.774194  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "38   1.000000  1.000000  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "39   0.714286  0.806452  (DecisionTreeClassifier(class_weight=None, cri...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [200,500,1000]\n",
    "max_features = ['sqrt',None]\n",
    "max_depth = [50,None]\n",
    "for feat in max_features:\n",
    "    for d in max_depth:\n",
    "        for n in n_estimators:\n",
    "            # Train and evaluate on training data\n",
    "            model_name = 'Random Forest: n={n}, feat={f}, depth={d}'.format(n=n,f=feat,d=d)\n",
    "            print(model_name)\n",
    "            forest = RandomForestClassifier(n_estimators=n,max_depth=d,max_features=feat, n_jobs=-1)\n",
    "            results = train_and_evaluate_model(X_train, y_train, X_test, y_test, forest, model_name, results)\n",
    "        \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Train:\n",
      "0.7695749440715883 0.8075117370892019 0.7350427350427351\n",
      "Test:\n",
      "0.7796610169491526 0.8214285714285714 0.7419354838709677\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/train</th>\n",
       "      <th>name</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=500, feat=None, depth=None</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>train</td>\n",
       "      <td>Random Forest: n=1000, feat=None, depth=None</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=1000, feat=None, depth=None</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>train</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.769575</td>\n",
       "      <td>0.807512</td>\n",
       "      <td>0.735043</td>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>test</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test/train                                          name        F1  \\\n",
       "37       test   Random Forest: n=500, feat=None, depth=None  0.727273   \n",
       "38      train  Random Forest: n=1000, feat=None, depth=None  1.000000   \n",
       "39       test  Random Forest: n=1000, feat=None, depth=None  0.757576   \n",
       "40      train                                   Naive Bayes  0.769575   \n",
       "41       test                                   Naive Bayes  0.779661   \n",
       "\n",
       "    Precision    Recall                                         Classifier  \n",
       "37   0.685714  0.774194  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "38   1.000000  1.000000  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "39   0.714286  0.806452  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "40   0.807512  0.735043  MultinomialNB(alpha=1.0, class_prior=None, fit...  \n",
       "41   0.821429  0.741935  MultinomialNB(alpha=1.0, class_prior=None, fit...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are no hyperparemters for this algorithm\n",
    "mnb = MultinomialNB()\n",
    "results = train_and_evaluate_model(X_train, y_train, X_test, y_test, mnb, \"Naive Bayes\", results)\n",
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: slack=2\n",
      "Train:\n",
      "0.7695749440715883 0.8075117370892019 0.7350427350427351\n",
      "Test:\n",
      "0.7796610169491526 0.8214285714285714 0.7419354838709677\n",
      "SVM: slack=1\n",
      "Train:\n",
      "0.7695749440715883 0.8075117370892019 0.7350427350427351\n",
      "Test:\n",
      "0.7796610169491526 0.8214285714285714 0.7419354838709677\n",
      "SVM: slack=0.1\n",
      "Train:\n",
      "0.7695749440715883 0.8075117370892019 0.7350427350427351\n",
      "Test:\n",
      "0.7796610169491526 0.8214285714285714 0.7419354838709677\n",
      "SVM: slack=0.05\n",
      "Train:\n",
      "0.7695749440715883 0.8075117370892019 0.7350427350427351\n",
      "Test:\n",
      "0.7796610169491526 0.8214285714285714 0.7419354838709677\n",
      "SVM: slack=0.01\n",
      "Train:\n",
      "0.7695749440715883 0.8075117370892019 0.7350427350427351\n",
      "Test:\n",
      "0.7796610169491526 0.8214285714285714 0.7419354838709677\n",
      "   test/train             name        F1  Precision    Recall  \\\n",
      "47       test   SVM: slack=0.1  0.779661   0.821429  0.741935   \n",
      "48      train  SVM: slack=0.05  0.769575   0.807512  0.735043   \n",
      "49       test  SVM: slack=0.05  0.779661   0.821429  0.741935   \n",
      "50      train  SVM: slack=0.01  0.769575   0.807512  0.735043   \n",
      "51       test  SVM: slack=0.01  0.779661   0.821429  0.741935   \n",
      "\n",
      "                                           Classifier  \n",
      "47  MultinomialNB(alpha=1.0, class_prior=None, fit...  \n",
      "48  MultinomialNB(alpha=1.0, class_prior=None, fit...  \n",
      "49  MultinomialNB(alpha=1.0, class_prior=None, fit...  \n",
      "50  MultinomialNB(alpha=1.0, class_prior=None, fit...  \n",
      "51  MultinomialNB(alpha=1.0, class_prior=None, fit...  \n"
     ]
    }
   ],
   "source": [
    "slacks = [2, 1, 0.1, 0.05, 0.01]\n",
    "for slack in slacks:\n",
    "    model_name = \"SVM: slack={slack}\".format(slack=slack)\n",
    "    svc_clf = LinearSVC(C=float(slack),loss='hinge')\n",
    "    results = train_and_evaluate_model(X_train, y_train, X_test, y_test, mnb, model_name, results)\n",
    "print(results.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "Now that we've evaluated a number of classifiers, we'll pick the best one, save its predictions, and do a further analysis on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/train</th>\n",
       "      <th>name</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight=None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight=None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=0.1</td>\n",
       "      <td>0.073770</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=0.1</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=0.5</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>LogisticRegression(C=0.5, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test/train                                     name        F1  Precision  \\\n",
       "0      train  Logistic Regression: penalty=l1, C=0.01  0.000000   0.000000   \n",
       "1       test  Logistic Regression: penalty=l1, C=0.01  0.000000   0.000000   \n",
       "2      train   Logistic Regression: penalty=l1, C=0.1  0.073770   0.900000   \n",
       "3       test   Logistic Regression: penalty=l1, C=0.1  0.176471   1.000000   \n",
       "4      train   Logistic Regression: penalty=l1, C=0.5  0.735849   0.821053   \n",
       "\n",
       "     Recall                                         Classifier  \n",
       "0  0.000000  LogisticRegression(C=0.01, class_weight=None, ...  \n",
       "1  0.000000  LogisticRegression(C=0.01, class_weight=None, ...  \n",
       "2  0.038462  LogisticRegression(C=0.1, class_weight=None, d...  \n",
       "3  0.096774  LogisticRegression(C=0.1, class_weight=None, d...  \n",
       "4  0.666667  LogisticRegression(C=0.5, class_weight=None, d...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test/train</th>\n",
       "      <th>name</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l2, C=1.0</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=1000, feat=sqrt, depth=None</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>test</td>\n",
       "      <td>SVM: slack=0.05</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>test</td>\n",
       "      <td>SVM: slack=0.1</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>test</td>\n",
       "      <td>SVM: slack=1</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>test</td>\n",
       "      <td>SVM: slack=2</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>test</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>test</td>\n",
       "      <td>SVM: slack=0.01</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l2, C=0.5</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>LogisticRegression(C=0.5, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=500, feat=sqrt, depth=None</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=500, feat=sqrt, depth=50</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=1000, feat=None, depth=None</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=500, feat=None, depth=50</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=1000, feat=None, depth=50</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=200, feat=None, depth=None</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=1000, feat=sqrt, depth=50</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=200, feat=sqrt, depth=None</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=200, feat=None, depth=50</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=500, feat=None, depth=None</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test</td>\n",
       "      <td>Random Forest: n=200, feat=sqrt, depth=50</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>LogisticRegression(C=0.5, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l2, C=0.1</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=0.1</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>LogisticRegression(C=0.1, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l2, C=0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight=None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>Logistic Regression: penalty=l1, C=0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight=None, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test/train                                          name        F1  \\\n",
       "15       test        Logistic Regression: penalty=l2, C=1.0  0.785714   \n",
       "27       test  Random Forest: n=1000, feat=sqrt, depth=None  0.779661   \n",
       "49       test                               SVM: slack=0.05  0.779661   \n",
       "47       test                                SVM: slack=0.1  0.779661   \n",
       "45       test                                  SVM: slack=1  0.779661   \n",
       "43       test                                  SVM: slack=2  0.779661   \n",
       "41       test                                   Naive Bayes  0.779661   \n",
       "51       test                               SVM: slack=0.01  0.779661   \n",
       "13       test        Logistic Regression: penalty=l2, C=0.5  0.777778   \n",
       "25       test   Random Forest: n=500, feat=sqrt, depth=None  0.758621   \n",
       "19       test     Random Forest: n=500, feat=sqrt, depth=50  0.758621   \n",
       "39       test  Random Forest: n=1000, feat=None, depth=None  0.757576   \n",
       "31       test     Random Forest: n=500, feat=None, depth=50  0.746269   \n",
       "33       test    Random Forest: n=1000, feat=None, depth=50  0.746269   \n",
       "35       test   Random Forest: n=200, feat=None, depth=None  0.738462   \n",
       "21       test    Random Forest: n=1000, feat=sqrt, depth=50  0.736842   \n",
       "23       test   Random Forest: n=200, feat=sqrt, depth=None  0.736842   \n",
       "29       test     Random Forest: n=200, feat=None, depth=50  0.727273   \n",
       "37       test   Random Forest: n=500, feat=None, depth=None  0.727273   \n",
       "17       test     Random Forest: n=200, feat=sqrt, depth=50  0.724138   \n",
       "7        test        Logistic Regression: penalty=l1, C=1.0  0.666667   \n",
       "5        test        Logistic Regression: penalty=l1, C=0.5  0.666667   \n",
       "11       test        Logistic Regression: penalty=l2, C=0.1  0.545455   \n",
       "3        test        Logistic Regression: penalty=l1, C=0.1  0.176471   \n",
       "9        test       Logistic Regression: penalty=l2, C=0.01  0.000000   \n",
       "1        test       Logistic Regression: penalty=l1, C=0.01  0.000000   \n",
       "\n",
       "    Precision    Recall                                         Classifier  \n",
       "15   0.880000  0.709677  LogisticRegression(C=1.0, class_weight=None, d...  \n",
       "27   0.821429  0.741935  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "49   0.821429  0.741935  MultinomialNB(alpha=1.0, class_prior=None, fit...  \n",
       "47   0.821429  0.741935  MultinomialNB(alpha=1.0, class_prior=None, fit...  \n",
       "45   0.821429  0.741935  MultinomialNB(alpha=1.0, class_prior=None, fit...  \n",
       "43   0.821429  0.741935  MultinomialNB(alpha=1.0, class_prior=None, fit...  \n",
       "41   0.821429  0.741935  MultinomialNB(alpha=1.0, class_prior=None, fit...  \n",
       "51   0.821429  0.741935  MultinomialNB(alpha=1.0, class_prior=None, fit...  \n",
       "13   0.913043  0.677419  LogisticRegression(C=0.5, class_weight=None, d...  \n",
       "25   0.814815  0.709677  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "19   0.814815  0.709677  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "39   0.714286  0.806452  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "31   0.694444  0.806452  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "33   0.694444  0.806452  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "35   0.705882  0.774194  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "21   0.807692  0.677419  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "23   0.807692  0.677419  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "29   0.685714  0.774194  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "37   0.685714  0.774194  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "17   0.777778  0.677419  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "7    0.782609  0.580645  LogisticRegression(C=1.0, class_weight=None, d...  \n",
       "5    0.782609  0.580645  LogisticRegression(C=0.5, class_weight=None, d...  \n",
       "11   0.923077  0.387097  LogisticRegression(C=0.1, class_weight=None, d...  \n",
       "3    1.000000  0.096774  LogisticRegression(C=0.1, class_weight=None, d...  \n",
       "9    0.000000  0.000000  LogisticRegression(C=0.01, class_weight=None, ...  \n",
       "1    0.000000  0.000000  LogisticRegression(C=0.01, class_weight=None, ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to only look at test scores\n",
    "# Then sort by F1\n",
    "results[results['test/train'] == 'test'].sort_values(by='F1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test/train                                                 test\n",
       "name                Random Forest: n=200, feat=sqrt, depth=None\n",
       "F1                                                     0.736842\n",
       "Precision                                              0.807692\n",
       "Recall                                                 0.677419\n",
       "Classifier    (DecisionTreeClassifier(class_weight=None, cri...\n",
       "Name: 23, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our highest-performing model is a **Logistic Regression Classifier** with l2 regularization and a regularization parameter of C=1.0. Let's now retrain that model and save its predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = results.iloc[15].Classifier\n",
    "print(clf)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.96      0.92        69\n",
      "          1       0.88      0.71      0.79        31\n",
      "\n",
      "avg / total       0.88      0.88      0.88       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we'll save the dataframe that also has predictions\n",
    "test_df.to_pickle('../stats_data/test_data_with_preds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowid</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>referenceXML</th>\n",
       "      <th>doc_class</th>\n",
       "      <th>subject</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No_1007_141227_06-18-95</td>\n",
       "      <td>\\n CT CHEST W/CONTRAST \\n ~ Reason: assess de...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;annot...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>141227</td>\n",
       "      <td>06-18-95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No_12344_140694_08-13-21</td>\n",
       "      <td>\\n CTA CHEST W&amp;W/O C&amp;RECONS, NON-CORONARY; CT...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;annot...</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>140694</td>\n",
       "      <td>08-13-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No_14176_126791_10-19-39</td>\n",
       "      <td>\\n CTA CHEST W&amp;W/O C&amp;RECONS, NON-CORONARY; CT...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;annot...</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>126791</td>\n",
       "      <td>10-19-39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No_15847_121459_06-07-77</td>\n",
       "      <td>\\n CTA ABD W&amp;W/O C &amp; RECONS; CTA PELVIS W&amp;W/O...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;annot...</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>121459</td>\n",
       "      <td>06-07-77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No_15847_121459_06-16-77</td>\n",
       "      <td>\\n CT ABDOMEN W/O CONTRAST; CT PELVIS W/O CON...</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\\n&lt;annot...</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>121459</td>\n",
       "      <td>06-16-77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rowid                      name  \\\n",
       "0      1   No_1007_141227_06-18-95   \n",
       "1      2  No_12344_140694_08-13-21   \n",
       "2      3  No_14176_126791_10-19-39   \n",
       "3      4  No_15847_121459_06-07-77   \n",
       "4      5  No_15847_121459_06-16-77   \n",
       "\n",
       "                                                text  \\\n",
       "0   \\n CT CHEST W/CONTRAST \\n ~ Reason: assess de...   \n",
       "1   \\n CTA CHEST W&W/O C&RECONS, NON-CORONARY; CT...   \n",
       "2   \\n CTA CHEST W&W/O C&RECONS, NON-CORONARY; CT...   \n",
       "3   \\n CTA ABD W&W/O C & RECONS; CTA PELVIS W&W/O...   \n",
       "4   \\n CT ABDOMEN W/O CONTRAST; CT PELVIS W/O CON...   \n",
       "\n",
       "                                        referenceXML  doc_class  subject  \\\n",
       "0  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<annot...          0        5   \n",
       "1  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<annot...          0       37   \n",
       "2  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<annot...          0       41   \n",
       "3  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<annot...          0       45   \n",
       "4  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<annot...          0       45   \n",
       "\n",
       "   HADM_ID CHARTDATE  pred  \n",
       "0   141227  06-18-95     0  \n",
       "1   140694  08-13-21     0  \n",
       "2   126791  10-19-39     0  \n",
       "3   121459  06-07-77     0  \n",
       "4   121459  06-16-77     0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's save just the predictions\n",
    "test_df = pd.read_pickle('../stats_data/test_data_with_preds.pkl')\n",
    "test_df['pred'] = y_pred_test\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the classifier\n",
    "with open('../stats_data/lin_reg.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "    \n",
    "# Save the vectorizer and testing data\n",
    "with open('../stats_data/test_data.pkl', 'wb') as f:\n",
    "    pickle.dump((X_test, y_test, vectorizer), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>doc_class</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No_1007_141227_06-18-95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No_12344_140694_08-13-21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No_14176_126791_10-19-39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No_15847_121459_06-07-77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No_15847_121459_06-16-77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  doc_class  pred\n",
       "0   No_1007_141227_06-18-95          0     0\n",
       "1  No_12344_140694_08-13-21          0     0\n",
       "2  No_14176_126791_10-19-39          0     0\n",
       "3  No_15847_121459_06-07-77          0     0\n",
       "4  No_15847_121459_06-16-77          0     0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = test_df[['name', 'doc_class', 'pred']]\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out.to_csv('../stats_data/test_preds.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion\n",
    "Our best performing classifier was a Logistic Regression. We ended up with an F1 of 0.79 for positive instances. This is a reasonably good score. In our final notebook we'll test our predictions for statistical significance and see if this classifier is significantly better than others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Up Next\n",
    "[Analysis](Analysis.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
