{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Summary\n",
    "In this project we tested the hypothesis that the vocabulary used to describe CT reports with fluid collections was significantly different than those without fluid collections. We used descriptive statistics to analyze the structure of reports. We utilized conditional probablities and Chi2 tests of independence to identify which terms in the vocabulary were the most indicitive of positive reports. We then trained and compared a number of ML algorithms to classify reports and compared the performance of each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "We found that ML algorithms with text features can effectively classify reports as containing or not containing fluid collections. A Student's t-test yielded a p-value of < 0.01, leading us to **reject the null hypothesis**. We initially selected a Logistic Regression Classifier as the best classifier due to its highest F1-score. However, we compared the performance of this model with several other high-performing models and tested for statistical significance using cross-validation and found that it was not significantly better. This led us to select a classifier with a slightly lower F1 but better balance between precision and recall. Our final model was a Random Forest Classifier with F1 = 0.78, Precision = 0.82, and Recall = 0.74."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "This is a relatively focused project. We focused only on Deep/Organ Space infections, but there are many types of SSIs and other adverse surgical events. Future projects should expand to these problems and test whether similar methods can yield effective results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "1. Zimlichman E, Henderson D, Tamir O, et al. Health care-associated infections: a meta-analysis of costs and financial impact on the US health care system. JAMA Intern Med. 2013 Dec 9-23;173(22):2039-2046. doi: 10.1001/jamainternmed.2013.9763.\n",
    "2. Etzioni DA, Lessow CL, Lucas HD, et al. Infectious Surgical Complications are Not Dichotomous: Characterizing Discordance Between Administrative Data and Registry Data. Ann Surg. 2016 Oct 17. doi: 10.1097/SLA.0000000000002041.\n",
    "3. Ko CY, Hall BL, Hart AJ, Cohen ME, Hoyt DB. The American College of Surgeons National Surgical Quality Improvement Program: achieving better and safer surgery. Jt Comm J Qual Patient Saf. 2015;41(5):199-204. PubMed PMID: 25977246.\n",
    "4. Price CS, Savitz LA. Improving the measurement of surgical site infection risk stratification/outcome detection. Final report (Prepared by Denver Health and its partners under Contract No. 290-2006-00-20). AHRQ Publication No. 12-0046-EF. Rockville, MD: Agency for Healthcare Research and Quality; 2012.\n",
    "5. Melton GB, Hripcsak G. Automated detection of adverse events using natural language processing of discharge summaries. Journal of the American Medical Informatics Association : JAMIA. 12(4):448–57. \n",
    "6. Friedman C, Alderson PO, Austin JH, Cimino JJ, Johnson SB. A general natural-language text processor for clinical radiology. J Am Med Inform Assoc. 1994 Apr;1(2):161–74. \n",
    "7. Penz JFE, Wilcox AB, Hurdle JF. Automated identification of adverse events related to central venous catheters. Journal of Biomedical Informatics. 2007;40(2):174–182.\n",
    "8. FitzHenry F, Murff HJ, Matheny ME, Gentry N, Fielstein EM, Brown SH, et al. Exploring the frontier of electronic health record surveillance: the case of postoperative complications. Medical care. 2013;51(6):509–16. \n",
    "9. Murff HJ, FitzHenry F, Matheny ME, Gentry N, Kotter KL, Crimin K, et al. Automated identification of postoperative complications within an electronic medical record using natural language processing. JAMA : the Journal of the American Medical Association. \n",
    "10. Chapman AB, Mowery DL, Swords DS, Chapman WW, Bucher BT. Detecting Evidence of Intra-Abdominal Surgical Site Infections from Radiology Reports Using Natural Language Processing. AMIA 2017 Annual Symposium\n",
    "11. Bouckaert RR. Choosing two learning algorithms based on calibrated tests. Proceedings of the Twentieth International Conference on Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
